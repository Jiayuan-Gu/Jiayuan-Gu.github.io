<!DOCTYPE HTML>
<html lang="en">

<head>
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
  <title>Jiayuan Gu</title>

  <meta name="author" content="Jiayuan Gu">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <link rel="stylesheet" type="text/css" href="css/stylesheet.css">
  <link rel="stylesheet" type="text/css" href="css/index.css">
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <!-- <script async src="https://www.googletagmanager.com/gtag/js?id=UA-125053794-2"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-125053794-2');
  </script> -->
</head>

<body>
  <div class="container">
    <div id="bio" class="d-flex align-items-center justify-content-between">
      <div class="block" style="width: 60%; vertical-align: middle;">
        <p class="text-center">
          <name>Jiayuan Gu</name>
        </p>
        <p>
          I am an Assistant Professor at <a href="https://sist.shanghaitech.edu.cn/gjy/main.htm">ShanghaiTech University</a>. My research topics include Embodied AI and 3D Vision. Specifically, I am interested in developing robust robot learning systems in both simulation and the real world.
        </p>
        <p>
          Prior to joining ShanghaiTech, I received my Ph.D. from Computer Science & Engineering (CSE) at UC San Diego, advised by <a href="http://cseweb.ucsd.edu/~haosu/">Prof. Hao Su</a>. I obtained my Bachelor degree at Peking University, advised by <a href="http://www.liweiwang-pku.com/">Prof. Liwei Wang</a>. Besides, I spent good time in Google DeepMind (Robotics), Facebook AI (Embodied AI), Waymo, Uber ATG, and MSRA.
        </p>
        <p>
          <!-- text in red -->
          <span class="highlight">Prospective students</span>:
          If you are interested in joining my group, please read <a href="application.html">this</a>.
        </p>
        <p class="text-center">
          <a href="mailto:gujy1@shanghaitech.edu.cn">Email</a> &nbsp/&nbsp
          <!-- <a href="mailto:jigu@ucsd.edu">Email</a> &nbsp/&nbsp -->
          <a href="https://scholar.google.com/citations?user=YH1v2uYAAAAJ&hl=en">Google Scholar</a> &nbsp/&nbsp
          <a href="https://github.com/Jiayuan-Gu">Github</a>
        </p>
      </div>

      <div class="block" style="width: 30%; max-width: 30%;">
        <img style="width:100%;max-width:100%" alt="profile photo" src="images/profile_photo_circle.png"></a>
      </div>
    </div>

    <div id="news" class="block">
      <heading>News</heading>
      <!-- <sup class="highlight">New</sup> -->
      <p>
        [2025.6] Our work <strong>CAST</strong> receives the SIGGRAPH 2025 Best Paper Award</a>.
      </p>
      <p>
        [2025.5] Co-organize the <a href="https://human-robot-scene.github.io/">workshop</a> on Human-Robot-Scene at ICCV 2025.
      </p>
      <p>
        [2024.4] I will join ShanghaiTech University as an Assistant Professor.
      </p>
      <p>
        [2024.1] <a href="#rt-trajectory">RT-Trajectory</a> is accepted to ICLR 2024 as a spotlight (5%).
      </p>
      <p>
        [2023.7] Co-organize the <a href="https://ai-workshops.github.io/interdisciplinary-exploration-of-gmpl/">GMPL workshop</a> at RSS 2023.
      </p>
      <p>
        [2023.1] Two papers are accepted to ICLR 2023.
      </p>
      <p>
        [2022.8] ManiSkill 2022 Challenge is open!
      </p>
      <p>
        [2022.6] I will give a talk at the CVPR 2022 tutorial <a href="https://ai-workshops.github.io/building-and-working-in-environments-for-embodied-ai-cvpr-2022/">Building and Working in Environments for Embodied AI</a>.
      </p>
      <p>
        [2022.4] Co-organize the first <a href="https://geometry.stanford.edu/voli/">VOLI workshop</a> at ECCV 2022.
      </p>
      <p>
        [2020.9] Two papers are accepted to NeurIPS 2020.
      </p>
      <p>
        [2020.7] Two papers (spotlight) are accepted to ECCV 2020.
      </p>
      <p>
        [2019.01.12] Codes for Multi-view PointNet for 3D Scene Understanding are released.
      </p>
      <!-- ...more news... -->
      <a href="" id="show-more-news" style="display:block;margin-top:8px;">Show more</a>
    </div>

    <div class="block">
      <!-- <heading>Research</heading> -->
      <heading>Selected Publications</heading>
      <p>To see the full list of my research papers, please visit my <a href="https://scholar.google.com/citations?user=YH1v2uYAAAAJ&hl=en">google scholar profile</a>.</p>
    </div>
    
    <div class="paper">
      <div class="thumbnail">
        <img src="images/publication/cast-teaser.png" alt="CAST">
      </div>
      <div class="content">
        <span class="title">CAST: Component-Aligned 3D Scene Reconstruction from an RGB Image</span>
        <div>
          Kaixin Yao*, Longwen Zhang*, Xinhao Yan, Yan Zeng, Qixuan Zhang, Wei Yang, Lan Xu, Jiayuan Gu, Jingyi Yu
        </div>
        <div>
          SIGGRAPH 2025 (Best Paper Award)
        </div>
        <div>
          <a href="https://sites.google.com/view/cast4">project website</a>
          /
          <a href="https://arxiv.org/abs/2502.12894">arXiv</a>
        </div>
      </div>
    </div>

    <div class="paper">
      <div class="thumbnail">
        <img src="images/publication/pointsam-outdoor-example.gif" alt="simpler-env">
      </div>
      <div class="content">
        <a href="">
          <span class="title">Point-SAM: Promptable 3D Segmentation Model for Point Clouds
          </span>
        </a>
        <div>
          Yuchen Zhou*, <strong>Jiayuan Gu*</strong>, Tung Yen Chiang, Fanbo Xiang, Hao Su
        </div>
        <div>
          ICLR 2025
        </div>
        <div>
          <a href="https://point-sam.github.io/">project website</a>
          /
          <a href="https://arxiv.org/abs/2406.17741">arXiv</a>
          /
          <a href="https://github.com/zyc00/Point-SAM">Code</a>
        </div>
      </div>
    </div>
    
    <div class="paper">
      <div class="thumbnail">
        <img src="images/publication/simpler-env-teaser.png" alt="simpler-env">
      </div>
      <div class="content">
        <a href="">
          <span class="title">Evaluating Real-World Robot Manipulation Policies in Simulation
          </span>
        </a>
        <div>
          Xuanlin Li*, Kyle Hsu*, <strong>Jiayuan Gu*</strong>, Karl Pertsch†, Oier Mees†, Homer Rich Walke, Chuyuan Fu, Ishikaa Lunawat, Isabel Sieh, Sean Kirmani, Sergey Levine, Jiajun Wu, Chelsea Finn, Hao Su‡, Quan Vuong‡, Ted Xiao‡
        </div>
        <div>
          CoRL 2024
          <!-- RSS 2024 Data Generation for Robotics Workshop (spotlight) -->
        </div>
        <div>
          <a href="https://simpler-env.github.io/">project website</a>
          /
          <a href="https://arxiv.org/pdf/2405.05941">arXiv</a>
          /
          <a href="https://github.com/simpler-env/SimplerEnv">Code</a>
        </div>
      </div>
    </div>

    <div class="paper">
      <div class="thumbnail">
        <img src="https://cseweb.ucsd.edu/~haosu/asset/images/paper_logos/12345+-teaser.gif" alt="One-2-3-45++">
      </div>
      <div class="content">
        <a href="">
          <span class="title">One-2-3-45++: Fast Single Image to 3D Objects with Consistent Multi-View Generation and 3D Diffusion</span>
        </a>
        <div>
          Minghua Liu*, Ruoxi Shi*, Linghao Chen*, Zhuoyang Zhang*, Chao Xu*, Xinyue Wei, Hansheng Chen, Chong Zeng, <strong>Jiayuan Gu</strong>, Hao Su
        </div>
        <div>
          CVPR 2024
        </div>
        <div>
          <a href="https://sudo-ai-3d.github.io/One2345plus_page/">project website</a>
        </div>
      </div>
    </div>

    <div class="paper">
      <div class="thumbnail">
        <img src="images/publication/rt1_vs_rtt.gif" alt="RT-Trajectory">
      </div>
      <div class="content" id="rt-trajectory">
        <a href="https://openreview.net/forum?id=F1TKzG8LJO">
          <span class="title">RT-Trajectory: Robotic Task Generalization via Hindsight Trajectory Sketches</span>
        </a>
        <div>
          <strong>Jiayuan Gu</strong>, Sean Kirmani, Paul Wohlhart, Yao Lu, Montserrat Gonzalez Arenas, Kanishka Rao, Wenhao Yu, Chuyuan Fu, Keerthana Gopalakrishnan, Zhuo Xu, Priya Sundaresan, Peng Xu, Hao Su, Karol Hausman, Chelsea Finn, Quan Vuong, Ted Xiao
        </div>
        <div>
          ICLR 2024 (spotlight)
          <!-- The Out-of-Distribution Generalization in Robotics at CoRL 2023 -->
        </div>
        <div>
          <a href="https://rt-trajectory.github.io/">project website</a>
          /
          <a href="https://arxiv.org/abs/2311.01977">arXiv</a>
          /
          <a href="https://deepmind.google/discover/blog/shaping-the-future-of-advanced-robotics/">blog</a>
        </div>
      </div>
    </div>

    <div class="paper">
      <div class="thumbnail">
        <img src="images/publication/rt-sketch.gif" alt="RT-Sketch">
      </div>
      <div class="content">
        <a href="">
          <span class="title">RT-Sketch: Goal-Conditioned Imitation Learning from Hand-Drawn Sketches</span>
        </a>
        <div>
          Priya Sundaresan, Quan Vuong, <strong>Jiayuan Gu</strong>, Peng Xu, Ted Xiao, Sean Kirmani, Tianhe Yu, Michael Stark, Ajinkya Jain, Karol Hausman, Dorsa Sadigh*, Jeannette Bohg*, Stefan Schaal*
        </div>
        <!-- <div>
          Under review
        </div> -->
        <div>
          <a href="https://rt-sketch.github.io/">project website</a>
        </div>
      </div>
    </div>

    <div class="paper">
      <div class="thumbnail">
        <img src="images/publication/ms2-workflow.png" alt="ManiSkill2 Open-source Recipe">
      </div>
      <div class="content">
        <a href="">
          <span class="title">An Open-source Recipe for Building Simulated Robot Manipulation Benchmarks</span>
        </a>
        <div>
          <strong>Jiayuan Gu</strong>, Linghao Chen, Zhiwei Jia, Fanbo Xiang, Hao Su
        </div>
        <div>
          <a href="https://www.robot-manipulation.org/icra-2023">ICRA 2023 COMPARE workshop</a>
        </div>
        <div>
          <a href="./pdf/icra23-compare.pdf">pdf</a>
        </div>
      </div>
    </div>

    <div class="paper">
      <div class="thumbnail">
        <img src="images/publication/maniskill2.gif" alt="ManiSkill2">
      </div>
      <div class="content">
        <a href="https://openreview.net/forum?id=b_CQDy9vrD1">
          <span class="title">ManiSkill2: A Unified Benchmark for Generalizable Manipulation Skills</span>
        </a>
        <div>
          <strong>Jiayuan Gu</strong>, Fanbo Xiang, et.al.
        </div>
        <div>
          ICLR 2023
        </div>
        <div>
          <a href="https://sapien.ucsd.edu/challenges/maniskill/2022/">Challenge website</a>
          /
          <a href="https://github.com/haosulab/ManiSkill2">code</a>
          /
          <a href="https://openreview.net/pdf?id=b_CQDy9vrD1">paper</a>
        </div>
      </div>
    </div>

    <div class="paper">
      <div class="thumbnail">
        <img src="images/publication/hab_m3.png" alt="Rearrangement">
      </div>
      <div class="content">
        <a href="https://openreview.net/forum?id=Z3IClM_bzvP">
          <span class="title">Multi-skill Mobile Manipulation for Object Rearrangement</span>
        </a>
        <div>
          <strong>Jiayuan Gu</strong>, Devendra Singh Chaplot, Hao Su, Jitendra Malik
        </div>
        <div>
          ICLR 2023 (spotlight)
          <!-- NeurIPS 2022 <a href="https://sites.google.com/view/deep-rl-workshop-neurips-2022">Deep RL workshop</a> -->
        </div>
        <div>
          <a href="https://sites.google.com/view/hab-m3">project website</a>
          /
          <a href="https://github.com/Jiayuan-Gu/hab-mobile-manipulation">code</a>
          /
          <a href="https://arxiv.org/abs/2209.02778">arxiv</a>
        </div>
        <div>
          Rank 1st in <a href="https://eval.ai/web/challenges/challenge-page/1820/leaderboard/4267">Habitat Rearrangement Challenge 2022</a>
        </div>
      </div>
    </div>

    <div class="paper">
      <div class="thumbnail">
        <img src="https://cseweb.ucsd.edu/~haosu/asset/images/paper_logos/teaser_v2.gif" alt="Part Reconstruction">
      </div>
      <div class="content">
        <a href="">
          <span class="title">Compositionally Generalizable 3D Structure Prediction</span>
        </a>
        <div>
          Songfang Han, <strong>Jiayuan Gu</strong>, Kaichun Mo, Li Yi, Siyu Hu, Xuejin Chen, Hao Su
        </div>
        <div>
          Preprint
        </div>
        <div>
          <a href="https://github.com/hansongfang/CompNet">code</a>
          /
          <a href="https://arxiv.org/abs/2012.02493">arXiv</a>
        </div>
      </div>
    </div>

    <div class="paper">
      <div class="thumbnail">
        <img src="https://cseweb.ucsd.edu/~haosu/asset/images/paper_logos/TongzhouNeurIPS.png" alt="Policy Refactorization">
      </div>
      <div class="content">
        <a href="">
          <span class="title">Refactoring Policy for Compositional Generalizability using Self-Supervised Object Proposals</span>
        </a>
        <div>
          Tongzhou Mu*, <strong>Jiayuan Gu*</strong>, Zhiwei Jia, Hao Tang, Hao Su
        </div>
        <div>
          NeurIPS 2020
        </div>
        <div>
          <a href="https://jiayuan-gu.github.io/policy-refactorization/">project website</a>
          /
          <a href="https://github.com/Jiayuan-Gu/policy-refactorization/">code</a>
          /
          <a href="https://arxiv.org/pdf/2011.00971.pdf">arXiv</a>
        </div>
      </div>
    </div>

    <div class="paper">
      <div class="thumbnail">
        <img src="https://cseweb.ucsd.edu/~haosu/asset/images/paper_logos/HaoTangNeurIPS.png" alt="IterGNN">
      </div>
      <div class="content">
        <a href="">
          <span class="title">Towards Scale-Invariant Graph-related Problem Solving by Iterative Homogeneous Graph Neural Networks</span>
        </a>
        <div>
          Hao Tang, Zhiao Huang, <strong>Jiayuan Gu</strong>, Bao-Liang Lu, Hao Su
        </div>
        <div>
          NeurIPS 2020
        </div>
        <div>
          <a href="https://github.com/haotang1995/IterGNN">code</a>
          /
          <a href="https://arxiv.org/abs/2010.13547">arXiv</a>
        </div>
      </div>
    </div>

    <div class="paper">
      <div class="thumbnail">
        <img src="images/publication/wssc.gif" alt="Weakly-supervised Shape Completion">
      </div>
      <div class="content">
        <a href="http://www.ecva.net/papers/eccv_2020/papers_ECCV/papers/123500273.pdf">
          <span class="title">Weakly-supervised 3D Shape Completion in the Wild</span>
        </a>
        <div>
          <strong>Jiayuan Gu</strong>, Wei-Chiu Ma, Sivabalan Manivasagam, Wenyuan Zeng, Zihao Wang, Yuwen Xiong, Hao
          Su, Raquel Urtasun
        </div>
        <div>
          ECCV 2020 (Spotlight)
        </div>
        <div>
          <a href="https://arxiv.org/abs/2008.09110">arXiv</a>
        </div>
      </div>
    </div>

    <div class="paper">
      <div class="thumbnail">
        <img src="https://people.csail.mit.edu/weichium/img/deep-optimizer-teaser.gif" alt="Deep Inverse Solver">
      </div>
      <div class="content">
        <a href="">
          <span class="title">Deep Feedback Inverse Problem Solver</span>
        </a>
        <div>
          Wei-Chiu Ma, Shenlong Wang, <strong>Jiayuan Gu</strong>, Sivabalan Manivasagam, Antonio Torralba, Raquel
          Urtasun
        </div>
        <div>
          ECCV 2020 (Spotlight)
        </div>
        <div>
          <a href="">arXiv</a>
        </div>
      </div>
    </div>

    <div class="paper">
      <div class="thumbnail">
        <img src="images/publication/mvpnet.svg" alt="MVPNet">
      </div>
      <div class="content">
        <a
          href="http://openaccess.thecvf.com/content_ICCVW_2019/papers/GMDL/Jaritz_Multi-View_PointNet_for_3D_Scene_Understanding_ICCVW_2019_paper.pdf">
          <span class="title">Multi-view PointNet for 3D Scene Understanding</span>
        </a>
        <div>
          Maximilian Jaritz, <strong>Jiayuan Gu</strong>, Hao Su
        </div>
        <div>
          ICCVW 2019 (Geometry Meets Deep Learning Workshop)
        </div>
        <div>
          <a href="https://github.com/maxjaritz/mvpnet">code</a>
          /
          <a href="https://arxiv.org/abs/1909.13603">arXiv</a>
        </div>
      </div>
    </div>

    <div class="paper">
      <div class="thumbnail">
        <img src="images/publication/neural_match.png" alt="Neural Match">
      </div>
      <div class="content">
        <a
          href="http://papers.nips.cc/paper/8167-towards-understanding-learning-representations-to-what-extent-do-different-neural-networks-learn-the-same-representation.pdf">
          <span class="title">To What Extent Do Different Neural Networks Learn the Same Representation: A Neuron
            Activation Subspace Match Approach
          </span>
        </a>
        <div>
          Liwei Wang, Lunjia Hu, <strong>Jiayuan Gu</strong>, Zhiqiang Hu, Yue Wu, Kun He, John Hopcroft
        </div>
        <div>
          NeurIPS 2019 (Spotlight)
        </div>
        <div>
          <a href="https://github.com/MeckyWu/subspace-match">code</a>
        </div>
      </div>
    </div>

    <div class="paper">
      <div class="thumbnail">
        <img src="images/publication/learn_region_features.png" alt="Learning Region Features">
      </div>
      <div class="content">
        <a
          href="https://openaccess.thecvf.com/content_ECCV_2018/papers/Jiayuan_Gu_Learning_Region_Features_ECCV_2018_paper.pdf">
          <span class="title">Learning Region Features for Object Detection</span>
        </a>
        <div>
          <strong>Jiayuan Gu</strong>, Han Hu, Liwei Wang, Yichen Wei, and Jifeng Dai
        </div>
        <div>
          ECCV 2018
        </div>
        <div>
          <a href="https://arxiv.org/abs/1803.07066">arXiv</a>
        </div>
      </div>
    </div>

    <div class="paper">
      <div class="thumbnail">
        <img src="images/publication/relation_network.png" alt="Relation Networks">
      </div>
      <div class="content">
        <a href="https://openaccess.thecvf.com/content_cvpr_2018/papers/Hu_Relation_Networks_for_CVPR_2018_paper.pdf">
          <span class="title">Relation Networks for Object Detection</span>
        </a>
        <div>
          Han Hu, <strong>Jiayuan Gu</strong>, Zheng Zhang, Jifeng Dai, and Yichen Wei
        </div>
        <div>
          CVPR 2018 (Oral)
        </div>
        <div>
          <a href="https://github.com/msracver/Relation-Networks-for-Object-Detection">code</a>
          /
          <a href="https://arxiv.org/abs/1711.11575">arXiv</a>
        </div>
      </div>
    </div>

    <div id="services" class="block">
      <heading>Services</heading>
      <p>
        Conference reviewer: CVPR (2019-2024), ICCV (2019, 2021), ECCV (2020,2024), NeurIPS (2020-2024), ICML (2021,2024), ICLR (2023-2024), AAAI (2021), ICRA (2022), CoRL (2024)
      </p>
      <p>Journal reviewer: PAMI, IJCV, IEEE T-RO</p>
    </div>

    <footer class="block text-center" style="margin-top: auto; display: block;">
      <p>Modified from <a href="https://jonbarron.info/">Joh Barron</a> and <a
          href="https://people.csail.mit.edu/weichium/">Wei-Chiu Ma</a>.
      </p>
    </footer>
  </div>

  <!-- Highlight latest news -->
  <script>
    document.addEventListener("DOMContentLoaded", function() {
      var newsBlock = document.getElementById("news");
      if (newsBlock) {
        var firstP = newsBlock.querySelector("p");
        if (firstP && !firstP.innerHTML.includes('highlight')) {
          firstP.innerHTML = '<sup class="highlight">New</sup> ' + firstP.innerHTML;
        }
      }
    });
  </script>

  <!-- Show more news -->
  <script>
    document.addEventListener("DOMContentLoaded", function() {
      var maxVisible = 5; // Number of news to show by default
      var newsItems = document.querySelectorAll("#news p");
      var showMore = document.getElementById("show-more-news");
      var expanded = false;
      if (newsItems.length <= maxVisible) {
        showMore.style.display = "none";
        return;
      }
      function updateNewsDisplay() {
        if (expanded) {
          for (var i = 0; i < newsItems.length; i++) {
            newsItems[i].style.display = "";
          }
          showMore.textContent = "Show less";
        } else {
          for (var i = 0; i < newsItems.length; i++) {
            newsItems[i].style.display = i < maxVisible ? "" : "none";
          }
          showMore.textContent = "Show more";
        }
      }
      updateNewsDisplay();
      showMore.addEventListener("click", function(e) {
        e.preventDefault();
        expanded = !expanded;
        updateNewsDisplay();
      });
    });
  </script>
</body>

</html>